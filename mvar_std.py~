import itertools

import numpy

class Mvar(object):
    """
    Multivariate normal distributions packaged to act like a vector.
        
    This is done with kalman filtering in mind, but is good for anything where 
        you need to track linked uncertianties across multiple variables.
    
    basic math (+,-,*,**) has been overloaded to work normally.
        
    The data is stored as an affine transformation:
        one large matrix containing the mean and standard-deviation matrixes.
        you can think of everything as being embeded on a sheet in a space 
        with 1 extra dimension the sheet is located 1 unit "up" along the 
        extra dimension.
        
        with this setup simple math operations (+,-,*,**) are can be done 
        almost directly on the affine transforms with little other work.
    
    the from* functions all create new instances from varous 
        common constructs.
    """

    ############## Creation
    def __init__(self,affine):
        """
        create an instance directly from an affine transform.
        the transform should be of the format:
        
            [ std,0]         [std.T,mean.T]
            [mean,1]   or    [    0,     1]
    
        the affine transform is the only real property in these things 
        everything else is calculated on the fly
        
        standard deviation is not a common term when dealing with these things,
        it's composed from 
        
        eigenvectors*diag(sqrt(eigenvalues))
        
        also note that: std*std.T==cov
        """
        self.affine=affine
    
    ############## alternate creation methods
    @staticmethod
    def from_mean_std(mean=None,std=None):
        mean=numpy.matrix(mean) if mean is not None else None
        std=numpy.matrix(std) if mean is not None else None
        
        #if only one input is supplied, assume the other is all zeros
        std = zeros((mean.size,mean.size)) if std is None else std
        mean = zeros((1,std.shape[0])) if mean is None else mean
        
        return Mvar(autostack([
            [ std, numpy.zeros([std.shape[0],1])],
            [mean, 1],
        ]))
            
    
    @staticmethod
    def from_mean_cov(mean = None,cov = None):
        #convert inputs to matrixes 
        cov = numpy.matrix(cov) if cov is not None else None
        mean = numpy.matrix(mean) if mean is not None else None
        
        #if only one input is supplied, assume the other is all zeros
        cov = zeros((mean.size,mean.size)) if cov is None else cov
        mean = zeros((1,std.shape[0])) if mean is None else mean
        
        scale,rotation = numpy.linalg.eigh(cov)
        
        #get the square root of the scales 
        scale = scale**0.5
        
        #create the affine transform, and from it the Mvar
        return Mvar.from_roto_scale(
            rotation = rotation,
            scale = scale,
            mean = mean,
        )
    
    @staticmethod
    def from_data(data, bias=0):
        """
        create an Mvar with the same mean and covariance as the supplied data
        with each row being a sample and each column being a dimenson
        
        remember numpy's default is to divide by (n-1) not (n) set bias to 1
        to normalize by 1
        """
        #convert the data to a matrix 
        data=numpy.matrix(data)
        
        #create the mvar from the mean and covariance of the data
        return Mvar.from_mean_cov(numpy.mean(data), numpy.cov(data, bias=bias))
    
    @staticmethod
    def from_roto_scale(rotation,scale,mean):
        """
        Rotation can be either a matrix or, if the mean is two dimensional, 
        it can be the rotation angle.
        
        Scale is like the standard deviation, and can be a vector, 
        or a diagonal matrix. Each element in the scale matrix is the scale 
        along the corresponding vector in the rotation matrix 
        """
        
        #convert everything to matrixes
        rotation,scale,mean=(
            numpy.matrix(data) 
            for data in (rotation,scale,mean)
        )
        
        #if the scale matrix is not square
        if scale.shape[0] != scale.shape[1]:
            #convert it to a diagonal matrix
            scale=numpy.matrix(numpy.diagflat(numpy.array(scale)))
        
        #if the rotatin matrix is a scalar, and we're working in 2 dimensions
        if rotation.size==1 and scale.shape==(2,2):
            # then rotation is the rotation angle, 
            #create the apropriate rotation matrix
            rotation=autostack([
                [ numpy.cos(rotation),numpy.sin(rotation)],
                [-numpy.sin(rotation),numpy.cos(rotation)],
            ])

        std=scale*rotation
        
        return Mvar(autostack([
            [ std, numpy.zeros([std.shape[0],1])],
            [mean, 1],
        ]))

    @staticmethod
    def stack(*mvars):
        """
        yes it works but be careful. Don't use this for reconnecting 
        something you've just calculated back to the data it was calculated 
        from. If you're trying to do that use a better matrix multiply, 
        so you don't loose the cross corelations
        """
        return Mvar.from_mean_cov(
            #stack the vectors horizontally
            numpy.hstack([mvar.mean for mvar in mvars]),
            #stack the covariances diagonally
            diagstack([mvar.std for mvar in mvars]),
        )
    
    ############ Eigen-stuf
    def get_rotate(self):
        return autostack([
            vector/numpy.sqrt(vector*vector.T) 
            for vector in self.std
        ])
        

    def get_scale(self):
        #the scale matrix is just the eigenvalues along the diagonal
        #the eigenvalues are for the covariance matrix, 
        #which is the square of the standard deviations..
        return numpy.diag([
            numpy.sqrt(numpy.sum(vector**2))
            for vector in numpy.array(self.std)
        ])

    def get_cov(self):
        return self.std.T*self.std
    
    def get_mean(self):
        return self.affine[-1,:-1]
    
    def get_std(self):
        return self.affine[:-1,:-1]
    
    ############ Properties
    rotate= property(fget=get_rotate)
    scale = property(fget=get_scale)
    cov   = property(fget=get_cov)
    mean  = property(fget=get_mean)
    std   = property(fget=get_std)

    
    #I'm not sure if it's reasonable to keep this....
    @property
    def T(self):
        return Mvar(self.affine.T)
    
    ############ Math
    def blend(*mvars):
        """
        'self' is part of *mvars 
        
        This blending function is not restricted to two inputs like the basic
        (wikipedia) version.
        
        am I extending it correctly?
        
        and is A.blend(blend(B,C)) == A.blend(B).blend(C)?
        I don't think so. (the outer Mvar gets more weight than the others)
        
        so if you have three independant measurments of the same thing what you
        want is blend(A,B,C)
        """
        return paralell(mvars)
        
    def __pow__(self,power):
        """
        I use this definition because 'blend' 
        becomes just a standard 'paralell'
        """
        std = self.std
        istd= std**(-1)
        
        self=self*istd
        if power > 0:
            return self*std**(power)
        elif power < 0:
            return self*istd**abs(power)
        else:
            return self

    def __add__(self,other):
        """
        when using addition keep in mind that rand()+rand() != (2*eye)*rand()
        if you want to scale it use matrix multiplication
        scalar multiplication however fits with addition:
            rand()+rand() == 2*rand()
        """
        if isinstance(other,Mvar):
            return Mvar.from_mean_cov(
                mean= (self.mean+other.mean),
                cov = (self.cov + other.cov),
            )
        else:
            raise NotImplemented("can only add Mvars to other Mvars")

    def __iadd__(self,other):
        if isinstance(other,Mvar):
            self.affine = (self+other).affine
        else:
            raise NotImplemented("can only add Mvars to othe Mvars")

    def __sub__(self,other):
        if isinstance(other,Mvar):
            return Mvar.from_mean_cov(
                mean= (self.mean-other.mean),
                cov = (self.cov - other.cov),
            )
        else:
            raise NotImplemented("can only subtract Mvars from other Mvars")
    
    def __isub__(self, other):
        if isinstance(other,Mvar):
            self.affine =(self - other).affine
        else:
            raise NotImplemented("can only subtract Mvars from other Mvars")

    def __mul__(self, other):
        if isinstance(other, Mvar):
            return self*other.std
            #!! is this right?
            #it fits with power (which was designed to help the implementation 
            #of paralell and blend)
        else:
            #if the other is iterable
            if hasattr(other, '__iter__'):
                #convert it to a matrix, and append a 1 to the bottom 
                #right corner 
                other=diagstack([numpy.matrix(other), 1])
                #and do the multiplication
                return Mvar(self.affine*other)
            else:
                #do scalar multiplication
                return Mvar.from_mean_std(
                    mean= self.mean*other,
                    std = self.std*numpy.sqrt(other),
                )
    
    def __rmul__(self,other):
        return (self.T*other.T).T

    def __imul__(self,other):
        if isinstance(other,Mvar):
            self*=other.std
        else:    
            #if the other is iterable  
            if hasattr(other,'__iter__'):
                other=diagstack([matrix(other),1])
                self.affine = self*other.affine
            else:
                #do scalar multiplication
                self.affine = Mvar.from_mean_std(
                    mean= self.mean*other,
                    std = self.std*numpy.sqrt(other),
                ).affine

    def __neg__(self):
        return (-1)*self
    
    ################# Non-Math python internals
    def __str__(self):
        return self.affine.__str__()
    
    def __repr__(self):
        return self.affine.__repr__()
        
############### Helpers
def diagstack(arrays):
    """
    output is two dimensional

    type matches first input, if it is a numpy array or matrix, 
    otherwise this returns a numpy array
    """
    arrays = list(arrays)
    
    atype = (
        type(arrays[0]) 
        if isinstance(arrays[0], numpy.ndarray) 
        else numpy.array
    ) 
    
    arrays = list(numpy.matrix(array) for array in arrays)

    shapes = numpy.vstack((
        (0,0),
        numpy.cumsum(
            numpy.array([array.shape for array in arrays]),
            axis = 0
        )
    ))

    result = numpy.zeros(shapes[-1,:])
    
    for (array,start,stop) in itertools.izip(arrays,shapes[:-1],shapes[1:]):
        result[start[0]:stop[0],start[1]:stop[1]] = array
    
    return atype(result)

def autostack(lists):
    """
    simplify matrix stacking
    vertically stack the results of horizontally stacking each list
    """
    lists= [[numpy.matrix(item) for item in row] for row in lists]
    
    return numpy.vstack(
        numpy.hstack(
            numpy.matrix(item) 
            for item in row
        ) 
        for row in lists
    )

def paralell(items):
    #resistors in paralell
    return sum(item**(-1) for item in items)**(-1)
